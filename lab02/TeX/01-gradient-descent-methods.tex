\section{Gradient descent methods}
    \subsection{A simple quadratic function}
        Let's \(\vec{x} \in \R^2\), \(\vec{x} = (x_1, x_2)^T\). I start focusing on a two dimensional function:
        \[f(\vec{x}) = x_1^2 + x_2^2\]
        \begin{figure}
            \centering
            \includegraphics[width=0.7\textwidth]{../Images/01-gradient-descent-simple-function-contours.png}
            \caption{Contour plot of the function \(f(\vec{x}) = x_{1}^{2} + x_{2}^{2}\), with \(x_1 \in [-5, +5]\) and \(x_2 \in [-5, +5]\)}
            \label{gradient-descent-simple-function-contours}
        \end{figure}
        \begin{figure}
            \centering
            \includegraphics[width=0.7\textwidth]{../Images/01-gradient-descent-simple-function-surface.png}
            \caption{Graph of the function \(f(\vec{x}) = x_{1}^{2} + x_{2}^{2}\), with \(x_1 \in [-5, +5]\) and \(x_2 \in [-5, +5]\)}
            \label{gradient-descent-simple-function-surface}
        \end{figure}
        I can plot the function to have an idea of its main features (see figures \ref{gradient-descent-simple-function-contours} and \ref{gradient-descent-simple-function-surface}). You can easily see that there is a local minimum: how can I find it? The easiest way is by performing a gradient descent. How does this method work? You just have to start with a guess \(\vec{x}^0\) for a local minimum of \(f(\vec{x})\) and than you have to take steps proportional to the negative of the gradient of the function at the current point. In other words, you have to consider the sequence \(x^0, x^1, ..., x^k, x^{k+1}, ...\) such that
        \[x^{k+1} = x^k - \alpha^k \nabla f(\vec{x})\]
        \(\alpha^k\) plays an important role since I would like to find the minimum as fast as I can. At the moment, let's keep it constant.\par
        Let's perform now some experiments.
        \begin{enumerate}
            \item In the first experiment I'm going to find a local minimum of the function \(f(\vec{x})\) using the gradient descent method with a constant value \(\alpha^k = 0.1\). I'm also goint to try with different starting points (\(\vec{x}^0 = (4,4)^T\), \(\vec{x}^0 = (-3,2)^T\) and \(\vec{x}^0 = (4,-3)^T\)).
            \begin{figure}
                \centering
                \includegraphics[width=0.7\textwidth]{../Images/01-gradient-descent-1st-experiment.png}
                \caption{Gradient descent method applied to the function \(f(\vec{x}) = x_{1}^{2} + x_{2}^{2}\) (with \(x_1 \in [-5, +5]\) and \(x_2 \in [-5, +5]\)), starting from three different points (\(\vec{x}^0 = (4,4)^T\), \(\vec{x}^0 = (-3,2)^T\) and \(\vec{x}^0 = (4,-3)^T\)), using \(\alpha = 0.1\) and performing \(100\) iterations}
                \label{gradient-descent-1st-experiment}
            \end{figure}
            As you can see in figure \ref{gradient-descent-1st-experiment}, the gradient descent algorithm converges to the minimum, no matter what the starting point is. It's also possible to see that we don't need \(100\) iterations to get really close to the minimum: in the next experiments we could try to find a way to stop the algorithm when it's close to the real minimum.
        \end{enumerate}